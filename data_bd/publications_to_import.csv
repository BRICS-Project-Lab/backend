id,created_at,updated_at,title,authors,abstract,journal_or_conference,publication_year,doi,url,owner_id
1,"2025-10-23 13:43:14.014286","2025-10-23 15:17:08.231618","Оценка финансово-экономического эффекта внедрения систем искусственного интеллекта в здравоохранении на примере платформы Webiomed","Прохоренко Н. Ф.","Одним из барьеров широкого применения систем искусственного интеллекта в здравоохранении является отсутствие финансового-экономического обоснования их внедрения. На примере опыта использования отечественной платформы Webiomed в решении задач профилактики сердечно-сосудистых заболеваний предложена модель оценки экономической эффективности. Общий потенциальный эффект составляет 117,9 млн. руб./1 млн. населения в год, что соответствует окупаемости проекта внедрения с первого года использования на популяции, начиная с 64 тыс.человек. Развитие внедрения рассматриваемой платформы в долгосрочной перспективе позволит повысить эффективность и обоснованность управленческих решений. Использование систем искусственного интеллекта с доказанным позитивным влиянием на эффективность использования финансовых ресурсов позволяет создать условия для достижения целевых показателей государственных программ в здравоохранении. Ключевые слова: системы искусственного интеллекта в здравоохранении, профилактика сердечно-сосудистых заболеваний, экономическая эффективность, система поддержки принятия врачебных решений, Webiomed","Менеджер здравоохранения",2024,10.21045/1811-0185-2024-11-77-87,https://cyberleninka.ru/article/n/otsenka-finansovo-ekonomicheskogo-effekta-vnedreniya-sistem-iskusstvennogo-intellekta-v-zdravoohranenii-na-primere-platformy,5
2,"2025-10-23 14:01:35.869163","2025-10-23 14:01:35.869192","Diagnostic accuracy of a commercially available deep-learning algorithm in supine chest radiographs following trauma","Gipson J, Tang V, Seah J, Kavnoudias H, Zia A, Lee R, Mitra B, Clements W.","Trauma chest radiographs may contain subtle and time-critical pathology. Artificial intelligence (AI) may aid in accurate reporting, timely identification and worklist prioritisation. However, few AI programs have been externally validated. This study aimed to evaluate the performance of a commercially available deep convolutional neural network – Annalise CXR V1.2 (Annalise.ai) – for detection of traumatic injuries on supine chest radiographs.","British Journal of Radiology",2022,10.1259/bjr.20210979,https://pmc.ncbi.nlm.nih.gov/articles/PMC10996416/#_ci93_,5
3,"2025-10-25 11:54:13.534197","2025-10-25 11:54:13.534236","Artificial Intelligence in Lung Cancer Detection: Clinical and Economic Assessment of Retrospective CT Analysis Two Years Post-COVID-19 Pandemic","Zukov, Ruslan & Safontsev, Ivan & Klimenok, Marina & Zabrodskaya, Tatyana & Merkulova, Natalya & Chernina, Valeria & Belyaev, Mikhail & Goncharov, Mikhail & Omelyanovskiy, Vitaly & Ulianova, Ksenia & Soboleva, Evgenia & Blokhina, Maria & Nalivkina, Elena & Gombolevskiy, Victor.","BACKGROUND: The use of chest computed tomography (CT) scans in Krasnoyarsk Krai, Russia, has increased since 2020, during the COVID-19 pandemic. This period also saw a 5.2% decrease in lung cancer (LC) incidence. The potential for missed LC cases has led to the investigation of new diagnostic methods, including the use of artificial intelligence (AI) for analyzing retrospective data. AIM: The study aimed to evaluate the effectiveness of an AI algorithm in identifying patients at high risk for LC using chest CT data from the COVID-19 pandemic. METHODS: A retrospective analysis was conducted on chest CTs from patients diagnosed with COVID-19 in the Krasnoyarsk region, using scans from November 1, 2020, to February 28, 2021. The AI algorithm ""Chest-IRA"" was applied to detect pulmonary nodules larger than 100 mm³. Radiologists classified the nodules detected by AI into three categories based on LC probability. The economic assessment of the AI algorithm included salary costs and potential savings from early LC treatment. RESULTS: Out of 10,500 CTs, the AI algorithm found nodules in 484 cases. Of these, 192 were highly likely to have LC, 103 showed no signs, and 60 were inconclusive. 112 patients with high or intermediate risk did not seek treatment. The AI confirmed lung cancer in 100 cases, 28.2% of those detected. Early-stage LC was found in 35% of cases, while 65% were at later stages. AI could save about 25.04 months of radiologist work, costing 2.43 million RUB. Early detection savings are estimated at 10.6 to 12.5 million RUB per 10,500 CTs, with a five-year economic impact of 259.4 to 305.1 million RUB. CONCLUSION: AI has proven effective in identifying pulmonary nodules amidst COVID-19, highlighting its potential to improve early detection and diagnostic accuracy, leading to earlier and more precise treatments.","Digital Diagnostics",2024,10.17816/DD630885,https://www.researchgate.net/publication/385556582_Artificial_Intelligence_in_Lung_Cancer_Detection_Clinical_and_Economic_Assessment_of_Retrospective_CT_Analysis_Two_Years_Post-COVID-19_Pandemic,
4,"2025-10-25 11:56:34.739047","2025-10-25 11:56:34.739071","Искусственный интеллект в травматологии и ортопедии. Реальность, фантазии или обман?","Середа Андрей Петрович, Джавадов Алисагиб Аббасович, Черный Александр Андреевич","Введение. В последние годы тема искусственного интеллекта (ИИ) в медицине весьма активно обсуждается как решение не просто перспективное, но и позволяющее улучшить какие-то результаты. Значительный рост интереса к системам ИИ в мире начался в первой половине — середине 2010-х гг., что позволило рассматривать вопрос применения таких систем на практике.
Цель исследования — провести анализ всех зарегистрированных в нашей стране как медицинское изделие программных продуктов, в том числе с технологией искусственного интеллекта, и оценить их применимость в области травматологии и ортопедии.
Материал и методы. В исследование были включены все программные продукты, имеющие регистрационное удостоверение медицинского изделия по коду ОКПД2 58.29.XX.XXX (Услуги по изданию прочего программного обеспечения). В государственном реестре медицинских изделий и организаций (индивидуальных предпринимателей), осуществляющих производство и изготовление медицинских изделий, по состоянию на 14 февраля 2024 г. по критерию включения мы обнаружили 111 зарегистрированных программных продуктов.
Результаты. Все зарегистрированные программные продукты мы предложили классифицировать следующим образом: системы, работающие с изображениями стандарта DICOM (47 шт., 42%), с лабораторными данными (20 шт., 18%), с изображениями при микроскопии (7 шт., 6%), с фотоизображениями (5 шт., 5%), медицинские информационные системы (4 шт., 4%), системы анализа текстовых данных (3 шт., 3%), системы поддержки принятия врачебных решений (3 шт., 3%), анализа ЭКГ/Холтер (2 шт., 2%), иные системы (16 шт., 14%). Систем, применимых в области травматологии и ортопедии, оказалось 4 шт. (4%).
Заключение. К сожалению, реальную применимость существующих решений в области травматологии и ортопедии можно расценить как минимальную в сравнении с пульмонологией, онкологией, лабораторной диагностикой, где программы с искусственным интеллектом уже добились значительных успехов.","Травматология и ортопедия России",2024,https://doi.org/10.17816/2311-2905-17468,https://cyberleninka.ru/article/n/iskusstvennyy-intellekt-v-travmatologii-i-ortopedii-realnost-fantazii-ili-obman,5
5,"2025-10-25 12:00:00.609928","2025-10-25 12:38:48.284795","Analysis of comprehensive genomic profiling of solid tumors with a novel assay for broad analysis in clinical diagnostics","Froyen, G., Volders, P.-J., Geerdens, E., Berden, S., Van der Meulen, J., De Cock, A., Vermeire, S., Van Huysse, J., de Barsy, M., Beniuga, G., de Leng, W.W.J., Jansen, A.M.L., Demers, I., Ozgur, Z., Dubbink, H.J., Speel, E.-J.M., van IJcken, W.F.J. and Maes, B.","Somatic multigene analysis by next-generation sequencing (NGS) is routinely integrated in medical oncology for clinical decision-making. However, with the fast-growing number of recommended and required genes as well as pan-cancer biomarkers, small panels have become vastly insufficient. Comprehensive genomic profiling (CGP) is, thus, required to screen for clinically relevant markers. In this multicentric study, we report on an extensive analysis across seven centers comparing the results of the novel OncoDEEP CGP assay with the diagnostically validated TruSight Oncology 500 (TSO500) kit on 250 samples. Overall concordance was 90% for clinically relevant gene variants and >96% for more complex biomarkers. Agreement for fusion detection was 94% for the 11 overlapping clinically actionable driver genes. The higher coverage uniformity of OncoDEEP compared to TSO500 allows users to pool more samples per sequencing run. Tertiary data analysis, including reporting, is integrated in the OncoDEEP solution, whereas this is an add-on for TSO500. Finally, we showed that, analytically, the OncoDEEP panel performs well, thereby advocating its use for CGP of solid tumors in diagnostic laboratories, providing an all-in-one solution for optimal patient management.","Molecular Oncology",2025,https://doi.org/10.1002/1878-0261.13812,https://febs.onlinelibrary.wiley.com/doi/10.1002/1878-0261.13812,5
6,"2025-10-25 12:38:15.465466","2025-10-25 12:38:15.465491","Evaluation of the Accuracy of Infer Read Software in Measuring the Volume of Pure Ground Glass Nodules in the Lung","LIANG Yuan, ZHANG Huihui, and WU Jianlin","Objective: To discuss the accuracy of the automatic measurement of the volume of pure ground glass nodules (pGGN) by the artificial intelligence pulmonary nodule detection software and the influencing factors of the measurement error. Methods: 170 pGGNs from 90 patients who underwent routine chest CT scan from January 1 to 31, 2021 in our hospital were selected in this retrospective study. The original CT scan data (including 1 mm thin-slice images) was sent to the AI server of Inference Technology to automatically measure the volume of lung nodules and record the measurement data. Two senior chest imaging diagnosticians manually carried out pGGNs layer-by-layer measurement and added the volume value, then took the average of three measurements as the ""gold standard"" data to compare with the AI measurement results, and then analyzed the influence of pGGN location, size, proximity and other factors on the AI measurement error. SPSS 26.0 was used for statistical analysis. Results: Among the total 170 pGGNs in the 90 patients in this study, 49 (28.82%) were in the right upper lobe, 21 (12.35%) were in the right middle lobe, 27 (15.88%) were in the right lower lobe, and left upper lobe 49 patients (28.82%) were involved, and 24 patients were in the lower lobe of the left lung (14.12%). Among the adjacent relationships of pGGN, 82 (48.24%) were completely located in the lung parenchyma without adjacency, 29 (17.06%) were close to the blood vessel, and 59 (34.70%) were close to the pleura. (1) There was no statistically significant difference in the volume values of pGGNs between two observers and the same observer at different time points. (2) For the measurement of the same pGGN, there was no statistically significant difference between the results of automatic measurement by AI and manual measurement and the correlation between the two was quite high (r=0.981), and the agreement was also very high (ICC value is 0.987). (3) The size, location, and adjacent relationship of pGGN lesions were not statistically significant for the error of AI volume measurement. Conclusions: The InferRead lung nodule measurement software shows high accuracy in the measurement of lung pGGN three-dimensional volume, which can be applied in clinical lung nodule diagnosis and related research. (2) For the measurement of the same pGGN volume, there was no difference between the results of automatic measurement by AI and manual measurement, and the correlation between them was quite high (r = 0.981), and the consistency was high (ICC value is 0.987). (3) The volume size, occurrence position and adjacent relationship of pGGN have no statistical significance on the error of AI volume measurement. Conclusion: The InferRead lung nodule detection software shows high accuracy in measuring the three-dimensional volume of lung pGGN, and can be applied to clinical diagnosis and related research of lung nodules.","CT Theory and Applications",2022,10.15953/j.ctta.2021.009,https://www.cttacn.org.cn/en/article/doi/10.15953/j.ctta.2021.009,5
7,"2025-10-25 12:40:39.385945","2025-10-25 12:41:14.800626","Independent evaluation of 12 artificial intelligence solutions for the detection of tuberculosis","Codlin AJ, Dao TP, Vo LNQ, Forse RJ, Van Truong V, Dang HM, Nguyen LH, Nguyen HB, Nguyen NV, Sidney-Annerstedt K, Squire B, Lönnroth K, Caws M.","There have been few independent evaluations of computer-aided detection (CAD) software for tuberculosis (TB) screening, despite the rapidly expanding array of available CAD solutions. We developed a test library of chest X-ray (CXR) images which was blindly re-read by two TB clinicians with different levels of experience and then processed by 12 CAD software solutions. Using Xpert MTB/RIF results as the reference standard, we compared the performance characteristics of each CAD software against both an Expert and Intermediate Reader, using cut-off thresholds which were selected to match the sensitivity of each human reader. Six CAD systems performed on par with the Expert Reader (Qure.ai, DeepTek, Delft Imaging, JF Healthcare, OXIPIT, and Lunit) and one additional software (Infervision) performed on par with the Intermediate Reader only. Qure.ai, Delft Imaging and Lunit were the only software to perform significantly better than the Intermediate Reader. The majority of these CAD software showed significantly lower performance among participants with a past history of TB. The radiography equipment used to capture the CXR image was also shown to affect performance for some CAD software. TB program implementers now have a wide selection of quality CAD software solutions to utilize in their CXR screening initiatives.","Scientific Reports",2021,10.1038/s41598-021-03265-0.,https://pmc.ncbi.nlm.nih.gov/articles/PMC8668935/,5
8,"2025-10-25 12:43:00.100465","2025-10-25 12:43:00.100491","Observer performance evaluation of the feasibility of a deep learning model to detect cardiomegaly on chest radiographs.","Ajmera P, Kharat A, Gupte T, Pant R, Kulkarni V, Duddalwar V, Lamghare P.","Background. Cardiothoracic ratio (CTR) is the ratio of the diameter of the heart to the diameter of the thorax. An abnormal CTR (>0.55) is often an indicator of an underlying pathological condition. The accurate prediction of an abnormal CTR chest X-rays (CXRs) aids in the early diagnosis of clinical conditions.
Purpose. We propose a deep learning (DL)-based model for automatic CTR calculation to assist radiologists with rapid diagnosis of cardiomegaly and thus optimise the radiology flow.
Material and Methods. The study population included 1012 posteroanterior CXRs from a single institution. The Attention U-Net DL architecture was used for the automatic calculation of CTR. An observer performance test was conducted to assess the radiologist’s performance in diagnosing cardiomegaly with and without artificial intelligence assistance.
Results. U-Net model exhibited a sensitivity of 0.80 [95% CI: 0.75, 0.85], specificity >99%, precision of 0.99 [95% CI: 0.98, 1], and a F1 score of 0.88 [95% CI: 0.85, 0.91]. Furthermore, the sensitivity of the reviewing radiologist in identifying cardiomegaly increased from 40.50% to 88.4% when aided by the AI-generated CTR.
Conclusion. Our segmentation-based AI model demonstrated high specificity (>99%) and sensitivity (80%) for CTR calculation. The performance of the radiologist on the observer performance test improved significantly with provision of AI assistance. A DL-based segmentation model for rapid quantification of CTR can therefore have significant potential to be used in clinical workflows by reducing radiologists’ burden and alerting to an abnormal enlarged heart early on.","Acta Radiologica Open",2022,10.1177/20584601221107345,https://pmc.ncbi.nlm.nih.gov/articles/PMC9309780/#sec21-20584601221107345,5
9,"2025-10-25 12:44:39.973685","2025-10-25 12:44:39.973712","Real-world analysis of artificial intelligence in musculoskeletal trauma","Ajmera P, Kharat A, Botchu R, Gupta H, Kulkarni V.","Musculoskeletal trauma accounts for a large percentage of emergency room visits and is amongst the top causes of unscheduled patient visits to the emergency room. Musculoskeletal trauma results in expenditure of billions of dollars and protracted losses of quality-adjusted life years. New and innovative methods are needed to minimise the impact by ensuring quick and accurate assessment. However, each of the currently utilised radiological procedures, such as radiography, ultrasonography, computed tomography, and magnetic resonance imaging, has resulted in implosion of medical imaging data. Deep learning, a recent advancement in artificial intelligence, has demonstrated the potential to analyse medical images with sensitivity and specificity at par with experts. In this review article, we intend to summarise and showcase the various developments which have occurred in the dynamic field of artificial intelligence and machine learning and how their applicability to different aspects of imaging in trauma can be explored to improvise our existing reporting systems and improvise on patient outcomes.","Journal of Clinical Orthopaedics and Trauma",2021,10.1016/j.jcot.2021.101573,https://pmc.ncbi.nlm.nih.gov/articles/PMC8427222/#sec9,5
10,"2025-10-25 12:46:47.727693","2025-10-25 12:46:47.727723","A deep learning approach for automated diagnosis of pulmonary embolism on computed tomographic pulmonary angiography","Ajmera, P., Kharat, A., Seth, J. et al.","Background. Computed tomographic pulmonary angiography (CTPA) is the diagnostic standard for confirming pulmonary embolism (PE). Since PE is a life-threatening condition, early diagnosis and treatment are critical to avoid PE-associated morbidity and mortality. However, PE remains subject to misdiagnosis.
Methods. We retrospectively identified 251 CTPAs performed at a tertiary care hospital between January 2018 to January 2021. The scans were classified as positive (n = 55) and negative (n = 196) for PE based on the annotations made by board-certified radiologists. A fully anonymized CT slice served as input for the detection of PE by the 2D segmentation model comprising U-Net architecture with Xception encoder. The diagnostic performance of the model was calculated at both the scan and the slice levels.
Results. The model correctly identified 44 out of 55 scans as positive for PE and 146 out of 196 scans as negative for PE with a sensitivity of 0.80 [95% CI 0.68, 0.89], a specificity of 0.74 [95% CI 0.68, 0.80], and an accuracy of 0.76 [95% CI 0.70, 0.81]. On slice level, 4817 out of 5183 slices were marked as positive for the presence of emboli with a specificity of 0.89 [95% CI 0.88, 0.89], a sensitivity of 0.93 [95% CI 0.92, 0.94], and an accuracy of 0.89 [95% CI 0.887, 0.890]. The model also achieved an AUROC of 0.85 [0.78, 0.90] and 0.94 [0.936, 0.941] at scan level and slice level, respectively for the detection of PE.
Conclusion. The development of an AI model and its use for the identification of pulmonary embolism will support healthcare workers by reducing the rate of missed findings and minimizing the time required to screen the scans.","BMC Medical Imaging",2022,https://doi.org/10.1186/s12880-022-00916-0,https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-022-00916-0#citeas,5
11,"2025-10-25 12:50:41.753754","2025-10-25 12:50:41.753779","Validation of a Deep Learning Model for Detecting Chest Pathologies from Digital Chest Radiographs","Ajmera P, Onkar P, Desai S, Pant R, Seth J, Gupte T, Kulkarni V, Kharat A, Passi N, Khaladkar S, Kulkarni VM.","Purpose: Manual interpretation of chest radiographs is a challenging task and is prone to errors. An automated system capable of categorizing chest radiographs based on the pathologies identified could aid in the timely and efficient diagnosis of chest pathologies. Method: For this retrospective study, 4476 chest radiographs were collected between January and April 2021 from two tertiary care hospitals. Three expert radiologists established the ground truth, and all radiographs were analyzed using a deep-learning AI model to detect suspicious ROIs in the lungs, pleura, and cardiac regions. Three test readers (different from the radiologists who established the ground truth) independently reviewed all radiographs in two sessions (unaided and AI-aided mode) with a washout period of one month. Results: The model demonstrated an aggregate AUROC of 91.2% and a sensitivity of 88.4% in detecting suspicious ROIs in the lungs, pleura, and cardiac regions. These results outperform unaided human readers, who achieved an aggregate AUROC of 84.2% and sensitivity of 74.5% for the same task. When using AI, the aided readers obtained an aggregate AUROC of 87.9% and a sensitivity of 85.1%. The average time taken by the test readers to read a chest radiograph decreased by 21% (p < 0.01) when using AI. Conclusion: The model outperformed all three human readers and demonstrated high AUROC and sensitivity across two independent datasets. When compared to unaided interpretations, AI-aided interpretations were associated with significant improvements in reader performance and chest radiograph interpretation time.","Diagnostics (Basel)",2023,10.3390/diagnostics13030557.,https://pmc.ncbi.nlm.nih.gov/articles/PMC9914339/,
12,"2025-10-25 12:52:43.052964","2025-10-25 12:52:43.052989","Can artificial intelligence (AI) be used to accurately detect tuberculosis (TB) from chest X-rays? An evaluation of five AI products for TB screening and triaging in a high TB burden setting","Zhi Zhen Qin, Shahriar Ahmed, Mohammad Shahnewaz Sarker, Kishor Paul, Ahammad Shafiq Sikder Adel, Tasneem Naheyan, Rachael Barrett, Sayera Banu, Jacob Creswell","Artificial intelligence (AI) products can be trained to recognize tuberculosis (TB)-related abnormalities on chest radiographs. Various AI products are available commercially, yet there is lack of evidence on how their performance compared with each other and with radiologists. We evaluated five AI software products for screening and triaging TB using a large dataset that had not been used to train any commercial AI products. Individuals (>=15 years old) presenting to three TB screening centers in Dhaka, Bangladesh, were recruited consecutively. All CXR were read independently by a group of three Bangladeshi registered radiologists and five commercial AI products: CAD4TB (v7), InferReadDR (v2), Lunit INSIGHT CXR (v4.9.0), JF CXR-1 (v2), and qXR (v3). All five AI products significantly outperformed the Bangladeshi radiologists. The areas under the receiver operating characteristic curve are qXR: 90.81% (95% CI:90.33-91.29%), CAD4TB: 90.34% (95% CI:89.81-90.87), Lunit INSIGHT CXR: 88.61% (95% CI:88.03%-89.20%), InferReadDR: 84.90% (95% CI: 84.27-85.54%) and JF CXR-1: 84.89% (95% CI:84.26-85.53%). Only qXR met the TPP with 74.3% specificity at 90% sensitivity. Five AI algorithms can reduce the number of Xpert tests required by 50%, while maintaining a sensitivity above 90%. All AI algorithms performed worse among the older age and people with prior TB history. AI products can be highly accurate and useful screening and triage tools for TB detection in high burden regions and outperform human readers.","BMJ Global Health",2022,https://doi.org/10.48550/arXiv.2006.05509,https://arxiv.org/abs/2006.05509,5
13,"2025-10-25 12:55:09.962356","2025-10-25 12:55:09.962383","Artificial intelligence for breast cancer screening in mammography (AI-STREAM): preliminary analysis of a prospective multicenter cohort study","Chang, YW., Ryu, J.K., An, J.K. et al.","Artificial intelligence (AI) improves the accuracy of mammography screening, but prospective evidence, particularly in a single-read setting, remains limited. This study compares the diagnostic accuracy of breast radiologists with and without AI-based computer-aided detection (AI-CAD) for screening mammograms in a real-world, single-read setting. A prospective multicenter cohort study is conducted within South Korea’s national breast cancer screening program for women. The primary outcomes are screen-detected breast cancer within one year, with a focus on cancer detection rates (CDRs) and recall rates (RRs) of radiologists. A total of 24,543 women are included in the final cohort, with 140 (0.57%) screen-detected breast cancers. The CDR is significantly higher by 13.8% for breast radiologists using AI-CAD (n = 140 [5.70‰]) compared to those without AI (n = 123 [5.01‰]; p < 0.001), with no significant difference in RRs (p = 0.564). These preliminary results show a significant improvement in CDRs without affecting RRs in a radiologist’s standard single-reading setting (ClinicalTrials.gov: NCT05024591).","Nature Communications",2025,https://doi.org/10.1038/s41467-025-57469-3,https://www.nature.com/articles/s41467-025-57469-3,5
14,"2025-10-25 12:56:46.861470","2025-10-25 12:56:46.861498","Evaluation of the clinical performance of an AI-based application for the automated analysis of chest X-rays","Niehoff JH, Kalaitzidis J, Kroeger JR, Schoenbeck D, Borggrefe J, Michael AE.","The AI-Rad Companion Chest X-ray (AI-Rad, Siemens Healthineers) is an artificial-intelligence based application for the analysis of chest X-rays. The purpose of the present study is to evaluate the performance of the AI-Rad. In total, 499 radiographs were retrospectively included. Radiographs were independently evaluated by radiologists and the AI-Rad. Findings indicated by the AI-Rad and findings described in the written report (WR) were compared to the findings of a ground truth reading (consensus decision of two radiologists after assessing additional radiographs and CT scans). The AI-Rad can offer superior sensitivity for the detection of lung lesions (0.83 versus 0.52), consolidations (0.88 versus 0.78) and atelectasis (0.54 versus 0.43) compared to the WR. However, the superior sensitivity is accompanied by higher false-detection-rates. The sensitivity of the AI-Rad for the detection of pleural effusions is lower compared to the WR (0.74 versus 0.88). The negative-predictive-values (NPV) of the AI-Rad for the detection of all pre-defined findings are on a high level and comparable to the WR. The seemingly advantageous high sensitivity of the AI-Rad is partially offset by the disadvantage of a high false-detection-rate. At the current stage of development, therefore, the high NPVs may be the greatest benefit of the AI-Rad giving radiologists the possibility to re-insure their own negative search for pathologies and thus boosting their confidence in their reports.","Scientific Reports",2023,https://doi.org/10.1038/s41598-023-30521-2,https://pmc.ncbi.nlm.nih.gov/articles/PMC9985819/,5
15,"2025-10-25 12:58:55.879754","2025-10-25 12:58:55.879845","Application value of a computer-aided diagnosis and management system for the detection of lung nodules","Chen J, Cao R, Jiao S, Dong Y, Wang Z, Zhu H, Luo Q, Zhang L, Wang H, Yin X","Background: Lung cancer is a leading cause of cancer mortality, where early detection of pulmonary nodules via computed tomography (CT) is critical. However, manual review is time-consuming and subject to human error. This study evaluates the performance of an artificial intelligence (AI)-based Computer-Aided Diagnosis (CAD) system for the automated detection of lung nodules. Methods: A retrospective, multi-center study was conducted on 1,002 low-dose chest CT scans from three hospitals. All scans were initially assessed manually by radiologists and subsequently analyzed by a deep learning-based CAD system (VoxelCloud Thorax software, version 1.0). The system utilized a Feature Pyramid Network for nodule detection and a 3D Residual Neural Network for classification. A panel of senior radiologists established the reference standard. Primary endpoints were the superiority of the CAD system's sensitivity and the equivalence of its false-positive rate compared to manual detection. Results: The CAD system demonstrated a significantly higher sensitivity for nodule detection compared to manual reading (90.19% vs. 49.88%, P<0.001). The increase in the false-positive rate was not statistically significant (0.30 vs. 0.24 false positives per case, P=0.12). The system showed particularly high performance in detecting small nodules (<8 mm) and medium-sized nodules (8-15 mm). The CAD system's nodule diameter measurements strongly correlated with the reference standard (r=0.85). The software achieved a 100% satisfaction rate for operational stability. Conclusion: The deep learning-based CAD system proved to be a highly effective and accurate tool for detecting lung nodules, offering a substantially higher sensitivity than manual assessment without a clinically significant increase in false positives. Its ability to function as a reliable ""junior reader"" can assist radiologists by reducing workload and potentially decreasing missed diagnoses, demonstrating strong potential for integration into clinical practice. The system has received Class III medical device certification from China's NMPA.","Quantitative Imaging in Medicine and Surgery",2023,10.21037/qims-22-1297.,https://pmc.ncbi.nlm.nih.gov/articles/PMC10585542/,5
16,"2025-10-25 13:00:45.165210","2025-10-25 13:00:45.165234","Artificial intelligence-assisted surgical simulation system based on non-enhanced computed tomography images in thoracoscopic pulmonary segmentectomies","Wang L, Hu J, Gao J, Zheng Z, Li S, Zhang Y, Liang H, Liu C, Xiang Z.","Background: Thoracoscopic pulmonary segmentectomy requires precise preoperative planning, which traditionally relies on time-consuming, manual three-dimensional (3D) reconstruction from contrast-enhanced computed tomography (CT) scans. This study evaluates a novel artificial intelligence (AI)-assisted surgical simulation system, LungDimensionGo, designed to automate and enhance surgical planning for lung segmentectomies using both non-enhanced and enhanced CT images. Methods: The LungDimensionGo system (V1.0) employs a deep learning pipeline utilizing the EfficientDet algorithm for lung nodule detection and an image segmentation algorithm based on Mamba-Unet and SegRefiner for fully automated 3D model reconstruction. The clinical performance of this AI-assisted method was compared against traditional CT post-processing techniques across preoperative, intraoperative, and postoperative phases. The study incorporated a retrospective cohort (n=125) and a prospective cohort (n=38) of patients who underwent segmentectomy. Results: The AI-assisted system demonstrated significant advantages over the traditional method. Preoperatively, it reduced 3D model reconstruction time from over 15 minutes to approximately 2.5 minutes (P<0.001). Intraoperatively, it achieved superior anatomical accuracy in reconstructing arteries (96.1% vs. 88.9%) and veins (96.6% vs. 89.7%), leading to shorter operative times and reduced blood loss (P<0.05). Postoperatively, patients in the AI-assisted group experienced shorter chest tube duration, reduced hospital stays, and fewer complications. Conclusions: The LungDimensionGo AI-assisted surgical simulation system is a highly efficient and accurate tool for thoracoscopic pulmonary segmentectomy planning. It significantly outperforms traditional methods by providing rapid, automated 3D reconstruction from non-contrast CT, enhancing intraoperative guidance, and improving key patient recovery metrics. This technology holds substantial potential to optimize surgical workflows and patient outcomes in lung cancer surgery.","Journal of Thoracic Disease",2025,10.21037/jtd-2025-375.,https://pmc.ncbi.nlm.nih.gov/articles/PMC12433101/,
17,"2025-10-25 13:02:34.994044","2025-10-25 13:02:34.994073","SVTNet: Automatic bone age assessment network based on TW3 method and vision transformer","Jindong Wu, Qunzheng Mi, Yi Zhang, Tongning Wu","Introduction: Bone age assessment (BAA) is a crucial procedure in pediatric medicine for diagnosing growth disorders. The Tanner-Whitehouse 3 (TW3) method is highly accurate but time-consuming and reliant on expert radiologists. This paper presents Yitu-AICARE, a novel, fully automated deep learning system designed to replicate the entire TW3 clinical workflow with high accuracy and clinical interpretability. Methods: Our end-to-end system processes a left-hand radiograph through a multi-stage pipeline. First, the hand is segmented using an Attention U-Net. Then, a Spatial Configuration Network (SCN) localizes 37 key anatomical points. From these, 20 regions of interest (13 RUS and 7 Carpal bones) are precisely cropped. Each region is classified by a dedicated Vision Transformer (ViT) model to determine its skeletal maturity score. The final bone age is calculated by summing these scores and converting them using the standard TW3 scale. The model was trained and evaluated on a dataset of 3,871 radiographs from a tertiary hospital, employing an Online Hard Sample Mining (OHSM) strategy to enhance performance. Results: The Yitu-AICARE system demonstrated a high level of accuracy, achieving a Mean Absolute Error (MAE) of 0.57 years in bone age estimation on the test set. Furthermore, the system showed a 94.2% probability that the prediction error would be less than one year. This performance is comparable to that of an experienced pediatric radiologist and was benchmarked against other state-of-the-art models. Conclusion: The Yitu-AICARE system successfully automates the complex TW3 BAA process, providing a robust, accurate, and clinically interpretable tool. By outputting individual bone maturity scores, it offers transparency into the assessment, aiding clinical decision-making. Its performance validates the potential of transformer-based architectures to advance the field of automated medical image analysis.","International Journal of Imaging Systems and Technology",2023,10.1002/ima.22990,https://onlinelibrary.wiley.com/doi/full/10.1002/ima.22990?casa_token=5a52mL35GUAAAAAA%3Aug108L5D7MMy-Y5uwMxKVXwM78c-A5pivJw2cwYDDU_arQwGMB7z9-PrmfurGoCtBqaJBlQSY-c2saymtw,
18,"2025-10-25 13:04:27.461891","2025-10-25 13:04:27.461917","Consistency between artificial intelligence and expert Greulich-Pyle atlas method for bone age assessment","Li Lei, Pan Qile, Cai Guang, Li Zhipeng","Background: The Greulich-Pyle (GP) atlas method is a widely accepted standard for bone age assessment (BAA), but its manual application is subject to inter-observer variability and is time-consuming. Artificial intelligence (AI) offers a potential solution for automating this process, improving both efficiency and consistency. Objective: This study aimed to validate the performance and clinical agreement of the DW-BADAS AI system, developed by Hangzhou Shenwu Bolian Technology Co., Ltd., against the assessments of an expert radiologist using the GP atlas method. Methods: A total of 1,322 left-hand radiographs from children and adolescents (672 males, 650 females) aged 6-15 years were retrospectively analyzed. Each radiograph was assessed for bone age independently by the DW-BADAS system and by a human expert with over 40 years of experience. Agreement was evaluated using the Mean Absolute Error (MAE), Pearson correlation coefficient, Bland-Altman analysis, and Kappa statistics for developmental categorization. Results: The DW-BADAS system demonstrated a high level of agreement with the expert reader. The overall MAE was 0.39 years for males and 0.32 years for females. A very strong positive correlation was observed between the AI and expert assessments (r = 0.991 for males, r = 0.992 for females, p < 0.0001). Bland-Altman analysis showed minimal bias, with 95% limits of agreement within ±1.04 years for males and ±0.83 years for females. The overall Kappa values for developmental categorization were 0.603 (males) and 0.659 (females), indicating substantial agreement. Conclusion: The DW-BADAS AI system shows high accuracy and excellent agreement with an expert radiologist in assessing bone age using the GP atlas method in children aged 6-15 years. Its implementation can standardize BAA, reduce reading time, and offer a reliable tool for use in pediatric endocrinology, sports medicine, and general clinical practice.","Chinese Journal of Tissue Engineering Research",2023,10.12307/2024.466,https://www.cjter.com/EN/abstract/abstract19462.shtml,
19,"2025-10-25 13:07:22.246244","2025-10-25 13:07:22.246271","Coronary Artery Vasculitis: A Nightmare Complicating Percutaneous Coronary Intervention","Tianhao Zhang, Juan Du, Hongkai Zhang, Xiaoming Zhang, Bokang Qiao, Tianlong Chen, Yujie Zhou, Lei Xu, Lili Pan, Yu Du","Background: Differentiating coronary artery vasculitis (CAV) from atherosclerotic coronary artery disease (CAD) is clinically critical yet challenging. Misdiagnosis can lead to recurrent complications following percutaneous coronary intervention (PCI). Coronary computed tomography angiography (CCTA) provides a non-invasive alternative, but its full potential for characterizing vessel wall pathology and inflammation requires advanced post-processing. Methods: uAI-CoronaryCTA (United Imaging) is an artificial intelligence-aided software platform for the comprehensive analysis of routine CCTA scans. It automatically quantifies key vascular characteristics, including: Plaque Burden: Calculating calcified (≥350 HU) and non-calcified (<350 HU) plaque volumes and percentages. High-Risk Plaque Features: Identifying features such as low-attenuation plaque, positive remodeling, spotty calcification, and the napkin-ring sign. Vessel Wall Assessment: Detecting morphological abnormalities including smooth concentric wall thickening, periarterial soft tissue thickening, and aneurysm formation. Perivascular Inflammation: Quantifying the Fat Attenuation Index (FAI) around the coronary arteries as a specific marker of pericoronary inflammation. Results: In clinical case series, uAI-CoronaryCTA successfully identified characteristic signs of CAV that were initially overlooked. Key differentiators from atherosclerosis included diffuse smooth concentric wall thickening, periarterial soft tissue thickening, and markedly elevated FAI values (typically between -70 and -50 HU). This comprehensive analysis facilitated the correct diagnosis of CAV in complex cases, preventing unnecessary repeat PCIs and guiding appropriate rheumatological management. Conclusion: uAI-CoronaryCTA provides a powerful, integrated tool for the differential diagnosis of CAV. By enabling simultaneous assessment of plaque characteristics, vessel wall morphology, and pericoronary inflammation from a standard CCTA, it raises clinical awareness of CAV and supports timely, accurate diagnosis, ultimately improving patient outcomes.","JACC: Case Reports",2025,10.1016/j.jaccas.2025.105062,https://www.sciencedirect.com/science/article/pii/S2666084925018418,
20,"2025-10-25 13:09:09.779485","2025-10-25 13:09:09.779510","Enhancing Radiologists’ Performance in Detecting Cerebral Aneurysms Using a Deep Learning Model: A Multicenter Study","Liyong Zhuo, Yu Zhang, Zijun Song, Zhanhao Mo, Lihong Xing, Fengying Zhu, Huan Meng, Lei Chen, Guoxiang Qu, Pengbo Jiang, Qian Wang, Ruonan Cheng, Xiaoming Mi, Lin Liu, Nan Hong, Xiaohuan Cao, Dijia Wu, Jianing Wang, Xiaoping Yin","Background: The detection of cerebral aneurysms from Computed Tomography Angiography (CTA) is a critical yet time-consuming and challenging task in radiology, with diagnostic accuracy being highly dependent on radiologist experience. This study aims to develop and validate a fully automated deep learning (DL) system, uAI-CTA-HeadNeckVessels, to assist radiologists in this process. Methods: The proposed DL model was trained and internally validated on a multicenter dataset of 3829 patients from 11 clinical centers. It comprises two core modules: an Aneurysm Detection Module (ADM) using a cascaded Feature Pyramid Network to identify aneurysms with 3D bounding boxes, and an Aneurysm Segmentation Module (ASM) based on VB-Net architecture to generate precise segmentation masks and reduce false positives. The system fully automates CTA post-processing, including volume rendering and multi-planar reformation. An independent external test set of 484 patients from three institutions was used for validation. The model's performance was evaluated alone and in conjunction with 10 radiologists (4 junior, 6 senior). Results: When used as an assistive tool, the uAI-CTA-HeadNeckVessels system significantly enhanced radiologists' diagnostic performance. It increased the area under the curve (AUC) at the patient level from 0.842 to 0.881 for junior radiologists (P=0.008) and from 0.853 to 0.895 for senior radiologists (P<0.001). Sensitivity at the lesion level improved significantly for both juniors (68.9% to 81.6%) and seniors (72.4% to 83.5%). The most notable improvement was observed in detecting small aneurysms (1-3 mm), with a 15.8% increase in sensitivity (P<0.001). Furthermore, the system drastically reduced image post-processing time by 90.8% and image interpretation time by 37.2%. Conclusion: The uAI-CTA-HeadNeckVessels DL model is an effective and efficient decision-support tool that significantly improves the diagnostic accuracy of radiologists in detecting cerebral aneurysms, particularly for less experienced readers and small, easily missed aneurysms, while substantially expediting the clinical workflow.","Academic Radiology",2024,10.1016/j.acra.2024.09.038,https://www.sciencedirect.com/science/article/pii/S1076633224006883,
21,"2025-10-25 13:11:07.871617","2025-10-25 13:11:07.871643","Agreement assessment of two automated platforms in computed tomography perfusion imaging for acute ischemic stroke","Xuehong Chu, Yingjie Shen, Wanwan Zhang, Yan Feng, Chuanjie Wu, Xunming Ji","Background: Automated computed tomography perfusion (CTP) analysis is crucial for acute ischemic stroke (AIS) management. While RAPID software is widely adopted, this study evaluates the agreement of a domestically developed platform, NeuBrainCARE (NBC), against this reference standard. Methods: A retrospective analysis was conducted on 306 AIS patients from 8 Chinese hospitals. All patients underwent CTP prior to thrombectomy. CTP datasets were processed using both NBC (v1.0, Neusoft, China) and RAPID (v5.1, iSchemaView, USA) software to calculate infarct core volume (ICV; CBF <30%), hypoperfusion volume (Tmax >6 s), and identify large core infarcts (>70 mL). Agreement was assessed using intraclass correlation coefficients (ICC), Bland-Altman analysis, and the Kappa coefficient. Results: No statistically significant differences were found between NBC and RAPID in measuring ICV (P=0.45), hypoperfusion volume (P=0.78), or large core identification (P=0.32). ICC values demonstrated excellent agreement for both ICV (0.98) and hypoperfusion volume (0.97). Bland-Altman analysis showed minimal mean bias, with over 94.4% of data points within limits of agreement. The concordance for large core infarct identification was excellent (Kappa = 0.92, P<0.001). Conclusion: The NeuBrainCARE software shows excellent agreement with the established RAPID software in quantifying key CTP parameters for AIS assessment. This validation supports NBC as a reliable and robust automated platform for clinical use in routine stroke care workflows.","Brain Circulation",2025,10.4103/bc.bc_47_25,https://journals.lww.com/brci/fulltext/9900/agreement_assessment_of_two_automated_platforms_in.26.aspx,
22,"2025-10-25 13:15:05.932572","2025-10-25 13:15:05.932598","AccuFFRct: Another Important Addition to the Arsenal of CT-FFR Solutions","Karády J.","Background: Coronary computed tomography angiography (CTA) is a first-line noninvasive test for diagnosing coronary artery disease (CAD) but lacks functional assessment. CT-derived fractional flow reserve (CT-FFR) bridges this gap by estimating the hemodynamic significance of coronary stenoses. Objective: To describe and evaluate the diagnostic performance of AccuFFRct, a novel, on-site CT-FFR platform that uses three-dimensional computational fluid dynamics (3D CFD) modeling. Methods: As reported in the ACCURATE-CT study (Li et al., JACC: Cardiovasc Interv. 2024), 339 patients with 404 vessels exhibiting intermediate stenosis (30-90% luminal narrowing) on coronary CTA were prospectively enrolled across 8 centers. AccuFFRct analysis was performed on-site and blinded to CTA results, with invasive FFR as the reference standard. Results: AccuFFRct demonstrated superior diagnostic accuracy compared to coronary CTA alone, with an area under the curve (AUC) of 0.93 (95% CI: 0.89-0.95) versus 0.77 (95% CI: 0.72-0.81), respectively (P < 0.001). High diagnostic performance was maintained across key patient subgroups (e.g., diabetes, stable angina), different coronary branches, and plaque types. Notably, AccuFFRct showed robust performance in the diagnostically challenging ""gray zone"" (CT-FFR values 0.70-0.80). Conclusion: AccuFFRct is a clinically available, on-site CT-FFR solution that provides high diagnostic accuracy for assessing the hemodynamic significance of intermediate coronary stenoses. Its use of on-site 3D CFD modeling offers a distinct technical advantage, potentially expanding access to functional coronary assessment. Further outcome and cost-effectiveness studies are warranted to solidify its role in clinical practice.","JACC: Cardiovascular Interventions",2024,10.1016/j.jcin.2024.07.023,https://www.sciencedirect.com/science/article/pii/S1936879824010094?via%3Dihub,
23,"2025-10-25 13:19:47.853180","2025-10-25 13:19:47.853211","The communication of artificial intelligence and deep learning in computer tomography image recognition of epidemic pulmonary infectious diseases","Weiwei Wang,Xinjie Zhao,Yanshu Jia ,Jiali Xu","uAI-Discover-NCP is an artificial intelligence (AI)-assisted diagnostic software designed for the automated analysis of chest computer tomography (CT) images in patients with pulmonary infectious diseases, such as COVID-19. Based on a deep convolutional neural network (CNN) architecture, specifically the AlexNet model, the system performs automated lesion detection, batch marking, and quantitative assessment of key pathological features. It calculates the total lesion volume, alongside the volume of internal ground-glass opacity (GGO) and solid consolidation areas, providing crucial data for objective diagnosis and progression monitoring. In a clinical study involving 200 patients, uAI-Discover-NCP demonstrated superior performance compared to manual detection by radiologists. The AI system achieved a detection rate of 99.76%, with a misdetection rate of 0.08% and a missed diagnosis rate of 0.16%, significantly outperforming manual methods which showed rates of 95.30%, 0.20%, and 4.50%, respectively. Statistical analysis confirmed the significance of these improvements (p<0.05). The system also provides 3D reconstruction capabilities for enhanced visualization of lesion anatomy. The results indicate that uAI-Discover-NCP can effectively identify and quantify pulmonary infectious disease lesions, offering a reliable and efficient tool to assist radiologists. It enhances diagnostic accuracy, reduces workload, and provides quantitative imaging support for clinical decision-making and public health management during epidemics.","PLOS ONE",2024,10.1371/journal.pone.0297578,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0297578,
24,"2025-10-25 13:21:45.898717","2025-10-25 13:21:45.898744","Research on the Application of Artificial Intelligence Software in Rib Fracture Diagnosis","Ван Сионхуэй, Лэй Юй, Ню Юань, Ли Цзин, Чжу Яньцзинь, Цзи Син, Хуан Сяоци","uAI-BoneCare is a commercially available, deep learning-based artificial intelligence (AI) software designed to assist in the detection and diagnosis of rib fractures (RFs) from chest computed tomography (CT) scans. Developed by Shanghai United Imaging Intelligence Co., Ltd., the system utilizes a multi-step pipeline involving convolutional neural networks (CNNs) such as V-Net and VRB-Net to perform automated rib segmentation, labeling, fracture detection, and classification into types (e.g., fresh, displaced, healing, old). Clinical validation studies demonstrate that uAI-BoneCare exhibits high diagnostic performance, with reported sensitivity of 95.7% and specificity of 99.7% at the lesion level. When used as an assistive tool for radiologists, it significantly enhances diagnostic sensitivity by 25.0% compared to standard double-reading by two radiologists, while maintaining non-inferior specificity. The AI system shows particular strength in identifying subtle, non-displaced fractures that are commonly missed by human readers and maintains consistent performance regardless of reporting time, unlike radiologists whose accuracy can fluctuate due to workload and fatigue. In conclusion, uAI-BoneCare represents a robust and effective tool for augmenting radiological diagnostics. Its implementation in a clinical setting can form an efficient ""AI-assisted additional-reader"" workflow, potentially replacing traditional double-reading to reduce radiologist workload while significantly improving fracture detection rates and overall diagnostic accuracy in patients with chest trauma.","Advances in Clinical Medicine",2022,10.12677/ACM.2022.121061,https://www.hanspub.org/journal/paperinformation?paperid=48284,
25,"2025-10-25 13:23:40.053755","2025-10-25 13:23:40.053783","Enhanced Detection of Prostate Cancer Lesions on Biparametric MRI Using Artificial Intelligence: A Multicenter, Fully-crossed, Multi-reader Multi-case Trial","Zhaoyu Xing, Jie Chen, Liang Pan, Danjiang Huang, Yingwei Qiu, Cuiyun Sheng, Yang Zhang, Qian Wang, Ruonan Cheng, Wei Xing, Jiule Ding","Objective: This study aimed to clinically validate the deep learning-based artificial intelligence system, uAI-ProstateMR, for the detection and localization of prostate cancer (PCa) lesions on biparametric MRI (bpMRI) and to evaluate its value as an assistive tool for radiologists. Methods: A multicenter, fully-crossed, multi-reader multi-case (MRMC) trial was conducted. The study involved 407 patients (204 with PCa, 268 lesions) from three institutions and 10 non-expert radiologists. The uAI-ProstateMR system utilizes a cascaded VB-Net architecture for prostate gland segmentation and a student-teacher VB-Net for lesion detection, processing T2-weighted, diffusion-weighted, and apparent diffusion coefficient images. Radiologist performance in detecting PCa was compared across three modes: unassisted reading, AI-assisted reading, and AI-alone. The primary endpoints were lesion-level sensitivity, case-level specificity, and the area under the alternative free-response receiver operating characteristic curve (AFROC-AUC). Results: AI-assisted reading demonstrated a significant improvement in diagnostic performance compared to unassisted reading. Lesion-level sensitivity increased substantially from 67.3% to 85.5% (difference 18.2%, p<0.001), while case-level specificity showed non-inferiority, increasing from 75.9% to 79.5%. The AFROC-AUC was significantly higher for aided reading (86.9% vs. 76.1%, p<0.001). The AI-alone system also achieved robust performance, with an AFROC-AUC of 83.1% and a lesion-level sensitivity of 88.4%. Subgroup analysis revealed that the AI system provided the greatest benefit in detecting smaller lesions (≤1 cm) and those with lower PI-RADS scores. Conclusion: The uAI-ProstateMR system significantly enhances the detection of prostate cancer on bpMRI, particularly for smaller and more challenging lesions. When used as an assistive tool, it improves radiologists' sensitivity without compromising specificity, demonstrating its potential as a valuable adjunct in the clinical workflow for prostate MRI interpretation.","Academic Radiology",2025,10.1016/j.acra.2025.06.038.,https://www.sciencedirect.com/science/article/pii/S107663322500618X,
26,"2025-10-25 13:27:39.300212","2025-10-25 13:27:39.300238","An artificial-intelligence-based age-specific template construction framework for brain structural analysis using magnetic resonance images","Gu D, Shi F, Hua R, Wei Y, Li Y, Zhu J, Zhang W, Zhang H, Yang Q, Huang P, Jiang Y, Bo B, Li Y, Zhang Y, Zhang M, Wu J, Shi H, Liu S, He Q, Zhang Q, Zhang X, Wei H, Liu G, Xue Z, Shen D; Consortium of Chinese Brain Molecular and Functional Mapping (CBMFM)","Title: uAI-BrainImaging-MRI: An Artificial Intelligence-Based Tool for Automated Intracranial Volumetry in Neurological Research Background: Quantitative analysis of brain structures from magnetic resonance imaging (MRI) is essential for studying neurological disorders. Automated, accurate, and reliable tools are needed to measure intracranial volumes efficiently in large-scale research studies.
Objective: This abstract describes uAI-BrainImaging-MRI, a software solution designed for the fully automated segmentation and volumetric analysis of intracranial compartments from 3D T1-weighted MRI data.
Methods: The tool leverages a deep learning-based pipeline to automatically delineate and calculate the volumes of key intracranial components, including total brain volume, ventricular volume, and extra-ventricular cerebrospinal fluid (CSF) volume. The total intracranial volume is derived as the sum of these compartments. The software outputs normalized relative volumes (e.g., relative ventricular volume - RVV) as ratios to the total intracranial volume, facilitating cross-subject comparisons. Its performance has been utilized and validated in peer-reviewed research, such as studies on idiopathic normal pressure hydrocephalus (iNPH).
Conclusion: uAI-BrainImaging-MRI represents a robust, AI-driven tool for automated intracranial volumetry. It provides researchers with a reliable method for quantifying brain structural changes, demonstrating its practical application and value in clinical neuroimaging research.","Human Brain Mapping",2023,10.1002/hbm.26126,https://pubmed.ncbi.nlm.nih.gov/36269199/,
27,"2025-10-25 13:29:30.854308","2025-10-25 13:29:30.854333","Study on Automatic Segmentation of CTV and OARs by AccuContour Software in Breast Cancer","GONG Xiaoqin, CHEN Fei, HU Jing, YOU Tao, ZHANG Kaijun, DAI Chunhua, ZHU Yaqun","Objective To explore the feasibility of U-net-based AccuContour (AC) software in the automatic segmentation of clinical target volume (CTV) and organs at risks (OARs) in breast cancer. Methods A total of 60 cases of early breast cancer after breast conserving surgery were selected. The CTV and OAR swere manually delineated by physician. Of them, 40 patients were randomly selected as the training set and the remaining 20 patients as the test set. Deep learning was carried out on the training set to set up an automatic segmentation mode (Model-ST). The sketching results were analyzed by using the dice similarity coefficient (DSC), Hausdorff distance (HD) and relative volume difference (RVD), and compared with the Model-AC provided by AC software. Results The DSC value of CTV in Model-ST was better than that of Model-AC (P<0.05). In the automatic segmentation comparison of OARs, the DSC values of bilateral lung, liver and esophagus of Model-AC were higher than those of Model-ST, the HD value of bilateral lungs and the RVD value of left lung, trachea and esophagus were lower than those of Model-ST, the HD and RVD value of heart is higher than Model-ST (P<0.05). Conclusion Compared with Model-AC, the Model-ST can achieve the automatic segmentation of CTV in breast cancer accurately, while the original Model-AC of AC software has better accuracy in automatic segmentation of OARs.","China Medical Devices",2022,10.3969/j.issn.1674-1633.2022.07.016,https://cs.china-cmd.org/zgylsb/EN/10.3969/j.issn.1674-1633.2022.07.016,
28,"2025-10-25 13:31:46.027941","2025-10-25 13:31:46.027967","Comparison Study of Three Softwares for Automatic Delineation of Brain Stem Structure of Patients with Head and Neck Neoplasms","WANG Min, HUO Xinying, SHI Feiyue, CHEN Lili, QIN Wei, ZHAO Huanyu, WEI Xiaowei","Abstract on PVMED-iCurve Software
Objective: To evaluate the accuracy of the domestic auto-segmentation software PVMED-iCurve (version 1.0) in delineating the brain stem structure for patients with head and neck neoplasms.
Methods: The study utilized computed tomography (CT) images of 20 patients. The brain stem contours generated automatically by PVMED-iCurve were compared against the gold standard of manual contours created in the Eclipse Treatment Planning System (TPS). The comparison was performed using the following metrics: Percent Volume Difference (ΔV%), Hausdorff Distance (HD), and Dice Similarity Coefficient (DSC).
Results: The PVMED-iCurve software demonstrated the following results for brain stem delineation:
ΔV%: 6.01% ± 17.77 (indicating a tendency to overestimate the volume)
HD: 7.74 ± 3.05 mm
DSC: 0.81 ± 0.05
All metrics showed statistically significant differences compared to the other tested software (AccuContour and DeepViewer). The automatic segmentation time was approximately 30 seconds.
Conclusion: PVMED-iCurve provides clinically acceptable automatic segmentation of the brain stem (DSC > 0.7). However, in this comparative study, its accuracy in terms of volume, position, and shape was lower than that of the AccuContour software. The program can be used to expedite the radiation therapy planning process, provided that the generated contours are subsequently verified and corrected by a physician.","China Medical Devices",2023,10.3969/j.issn.1674-1633.2023.07.002,https://cs.china-cmd.org/zgylsb/EN/10.3969/j.issn.1674-1633.2023.07.002,
29,"2025-10-25 13:36:06.094350","2025-10-25 13:36:06.094374","A fully automated noncontrast CT 3‐D reconstruction algorithm enabled accurate anatomical demonstration for lung segmentectomy","Xiuyuan Chen, Zhenfan Wang, Qingyi Qi, Kai Zhang, Xizhao Sui, Xun Wang, Wenhan Weng, Shaodong Wang, Heng Zhao, Chao Sun, Dawei Wang, Huajie Zhang, Enyou Liu, Tong Zou, Nan Hong, Fan Yang","Background: Three-dimensional reconstruction of chest computerized tomography (CT) excels in intuitively demonstrating anatomical patterns for pulmonary segmentectomy. However, current methods are labor-intensive and rely on contrast CT. We hereby present a novel fully automated reconstruction algorithm based on noncontrast CT and assess its performance both independently and in combination with surgeons.
Methods: A retrospective pilot study was performed. Patients between May 2020 to August 2020 who underwent segmentectomy in our single institution were enrolled. Noncontrast CTs were used for reconstruction. In the first part of the study, the accuracy of the demonstration of anatomical variants by either automated or manual reconstruction algorithm were compared to surgical observation, respectively. In the second part of the study, we tested the accuracy of the identification of anatomical variants by four independent attendees who reviewed 3-D reconstruction in combination with CT scans.
Results: A total of 20 cases were enrolled in this study. All segments were represented in this study with two left S1-3, two left S4 + 5, one left S6, five left basal segmentectomies, one right S1, three right S2, 1 right S2b + 3a, one right S3, two right S6 and two right basal segmentectomies. The median time consumption for the automated reconstruction was 280 (205-324) s. Accurate vessel and bronchial detection were achieved in 85% by the AI approach and 80% by Mimics, p = 1.00. The accuracy of vessel classification was 80 and 95% by AI and manual approaches, respectively, p = 0.34. In real-world application, the accuracy of the identification of anatomical variant by thoracic surgeons was 85% by AI+CT, and the median time consumption was 2 (1-3) min.
Conclusions: The AI reconstruction algorithm overcame defects of traditional methods and is valuable in surgical planning for segmentectomy. With the AI reconstruction, surgeons may achieve high identification accuracy of anatomical patterns in a short time frame.","Thorac Cancer",2022,10.1111/1759-7714.14322,https://pmc.ncbi.nlm.nih.gov/articles/PMC8930461/,
30,"2025-10-25 13:39:30.751767","2025-10-25 13:39:30.751793","КОМПАРАТИВНОЕ ИССЛЕДОВАНИЕ РЕЗУЛЬТАТОВ АНАЛИЗА ДАННЫХ ЦИФРОВОЙ МАММОГРАФИИ СИСТЕМЫ НА ОСНОВЕ ИСКУССТВЕННОГО ИНТЕЛЛЕКТА «ЦЕЛЬС» И ВРАЧЕЙ-РЕНТГЕНОЛОГОВ","Карпов О. Э., Бронов О. Ю., Капнинский А. А., Павлович П. И., Абович Ю. А., Субботин С. А., Соколова С. В., Рычагова Н. И., Милова А. В., Никитин Е. Д.","В статье рассматривается возможности использования системы анализа маммологических изображений «Цельс», использующей технологии искусственного интеллекта, для обнаружения злокачественных новообразований молочной железы при проведении скрининговых маммографических исследований. Представлены результаты ретроспективного когортного исследования, выполненного на группе из 49 пациентов, проходивших скрининг в ФГБУ «НМХЦ имени Н.И. Пирогова» Минздрава России (Пироговский Центр) и имеющих верифицированный диагноз злокачественного поражения по данным гистологического исследования. Получены количественные характеристики анализа цифровых маммограмм системой «Цельс». В частности, злокачественные новообразования были выявлены в 92% случаях, полное совпадение заключений с группой врачей-рентгенологов, специализирующихся в маммографии, было сделано в 90% случаев. Приведены результаты сравнительного клинического разбора наиболее сложных для диагностирования случаев. Показана целесообразность использования системы «Цельс» для аналитической поддержки врачей-рентгенологов при скрининговых маммографических исследованиях и определены сценарии их использования.","Вестник Национального медико-хирургического Центра им. Н. И. Пирогова",2021,10.25881/20728255_2021_16_2_86,https://cyberleninka.ru/article/n/komparativnoe-issledovanie-rezultatov-analiza-dannyh-tsifrovoy-mammografii-sistemy-na-osnove-iskusstvennogo-intellekta-tsels-i,
32,"2025-10-25 14:51:10.351556","2025-10-25 17:11:39.215111","Опыт разработки и внедрения системы поиска онкологических образований с помощью искусственного интеллекта на примере рентгеновской компьютерной томографии легких","Дрокин И. С., Еричева Е. В., Бухвалов О. Л., Пилюс П. С., Малыгина Т. С., Синицын В. Е.","Рассмотрен опыт создания и внедрения информационной системы на базе искусственного интеллекта «Botkin.AI» для выявления узлов и очагов в легких по данным КТ. Описаны основные параметры математических моделей, разработанных для системы, представлены результаты пилотных проектов ее практического применения в нескольких регионах Российской Федерации. Приведены примеры ее применения для выявления узлов в легких различных размеров и локализации. Во время проведения пилотных проектов в регионах были выявлены 7 пациентов с высоким подозрением ЗНО легких. Полученные результаты и опыт показывают, что применение системы Botkin.AI можно использовать как для целей реализации региональных программ скрининга рака легкого, так и в качестве дополнительного инструмента повышения выявляемости рака легкого при внедрении автоматического пересмотра массивов данных КТ грудной клетки, вне зависимости от показаний, по которым были сделаны эти исследования.","Врач и информационные технологии.",2019,-,https://cyberleninka.ru/article/n/opyt-razrabotki-i-vnedreniya-sistemy-poiska-onkologicheskih-obrazovaniy-s-pomoschyu-iskusstvennogo-intellekta-na-primere-rentgenovskoy/viewer,5
